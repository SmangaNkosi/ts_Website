---
title: Computation of the MFCC feature extraction method
subtitle: You Learn by Doing
description: Brief summaries of various things I learned.
image: mfcc2.jpg  
author: Tsepo Nkosi
date: '2024-09-24'
categories: [Signal processing, python, scipy]
format:
  html:
    math: true
open-graph:
  description: You Learn by Doing
  image: mfcc2.jpg  
reading-time: 10 min
---

MFCC is a method of extracting feature that converts sound into a voice vector. This method provides a representation of the short-term power spectrum of the signal. The motivations for using MFCC is its closeness with human hearing.

The steps of computing the MFCC are: 1. pre-emphasis 2. sampling and windowing 3. DFT 4. Mel-filter bank 5. log 6. DCT

![Steps for computing the MFCC](audio_processing_diagram.png)

::: panel-tabset
# Pre-emphasis

This step emphasizes the high-frequency component of our signal. The audio signal is passed through a highpass filter. Mathematically this is formulated as such $x_{pe}[n] = x_{in}[n] - \alpha x_{in}[n-1]$ where $x_{in}[n]$ is the input audio signal, "$\alpha$" is the filter constant, $a\in [0.9,1]$. $x_{pe}[n]$ is the filtered audio signal.

The python implementation of the pre-emphasis filter

```         
x_ep = numpy.append(x_in[0], x_in[1:] - alpha * x_in[:-1])
```

for most speech processing contexts, alpha is usually sated to `0.95` or `0.97`

# Framing and Windowing

As speech is not a stationary signal, it is divided into overlapped frames within which the signal is assumed to be stationary. For speech signal, the frames range between 20-40ms with 50% overlapped frames. If we choose a frame size of 20ms, ```f_size = 0.02```. then our overlap would be 10ms, ```f_stride = 0.01```.

Mathematically framing is defined as $x_{\text{fw}}= [x_{pe}(n)w(pW - n)]*h(n)$ 
where $w(n)$ is a windowed function of length  $W$.

```{}
f_length, f_step = f_size * sample_rate, f_stride * sample_rate 
x_length = len(x_pe)
f_length = int(round(f_length))
f_step = int(round(f_step))
num_f = int(numpy.ceil(float(numpy.abs(x_length - f_length)) / f_step)) 

pad_x_length = num_f * f_step + f_length
z = numpy.zeros((pad_x_length - x_length))
pad_x = numpy.append(x_pe, z)

indices = numpy.tile(numpy.arange(0, f_length), (num_f, 1)) + numpy.tile(numpy.arange(0,num_f * f_step, f_step), (f_length, 1)).T
x_f = pad_signal[indices.astype(numpy.int32, copy=False)]


```

now we apply the hamming function

```{}

x_fw *= numpy.hamming(f_length)

```


# Discrete Fourier Transform (DFT)

The DFT converts a signal from the time-domain into frequency-domain.
:::
