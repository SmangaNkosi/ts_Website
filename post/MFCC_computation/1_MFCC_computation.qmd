---
title: Computation of the MFCC feature extraction method
subtitle: You Learn by Doing
description: Brief summaries of various things I learned.
image: mfcc2.jpg  
author: Tsepo Nkosi
date: '2024-09-24'
categories: [Signal processing, python, scipy]
format:
  html:
    math: true
open-graph:
  description: You Learn by Doing
  image: mfcc2.jpg  
reading-time: 10 min
---

MFCC is a method of extracting feature that converts sound into a voice vector. This method provides a representation of the short-term power spectrum of the signal. The motivations for using MFCC is its closeness with human hearing.

The steps of computing the MFCC are: 1. pre-emphasis 2. sampling and windowing 3. DFT 4. Mel-filter bank 5. log 6. DCT

![Steps for computing the MFCC](audio_processing_diagram.png)

::: panel-tabset
# Pre-emphasis

This step emphasizes the high-frequency component of our signal. The audio signal is passed through a highpass filter. Mathematically this is formulated as such $x_{pe}[n] = x_{in}[n] - \alpha x_{in}[n-1]$ where $x_{in}[n]$ is the input audio signal, "$\alpha$" is the filter constant, $a\in [0.9,1]$. $x_{pe}[n]$ is the filtered audio signal.

The python implementation of the pre-emphasis filter 

```{}
x_ep = numpy.append(x_in[0], x_in[1:] - alpha * x_in[:-1])
```

for most speech processing contexts, alpha is usually sated to ```0.95 ``` or ```0.97 ```


# Sampling & windowing

This step divides the signal into segments and smooths their ends. The audio signal is divided into segments of length 20-30ms called frames. This segmenting of the audio signal may/will result in discontinuities or overlaps between successive frames. Windowing techniques are applied,i.e. Hamming, smoothing the ends of the frames thus avoiding discontinuities. Mathematically this is $y[n] = x[n]\times w[n]$

where $w[n]$ is the windowing function.

# Discrete Fourier Transform (DFT)

The DFT converts a signal from the time-domain into frequency-domain.
:::
